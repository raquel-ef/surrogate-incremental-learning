{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify sys.path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import random\n",
    "import config.config as config\n",
    "from src.data_processing import read_arff, preprocess_data\n",
    "from src.utils import generate_random_attribute_combinations\n",
    "from src.evaluation import create_surrogate_model_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATA_PATH = os.path.join('..', 'data', config.DATASET_NAME)\n",
    "\n",
    "dataset = read_arff(DATA_PATH)\n",
    "df_dict = preprocess_data(dataset)\n",
    "\n",
    "train_X_timeseries, train_Y_timeseries, val_X_timeseries, val_Y_timeseries, test_X_timeseries, test_Y_timeseries = df_dict['timeseries']\n",
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = df_dict['normalized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the dataset for the surrogated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_combinations = generate_random_attribute_combinations(config.N_ATTRIB, config.N_RANDOM_COMBINATIONS)\n",
    "surrogate_dataset = create_surrogate_model_dataset(random_combinations, train_X, train_Y, val_X, val_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "surrogate_dataset.to_pickle(f'../variables/{config.DATASET_SAVE_NAME}-surrogate-dataset.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the surrogated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load surrogate dataset\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-surrogate-dataset.pickle', 'rb') as f:\n",
    "    surrogate_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_dataset_X = [i.reshape(1, -1) for i in surrogate_dataset['Attributes']]\n",
    "surrogate_dataset_X = np.asanyarray(surrogate_dataset_X).reshape(len(surrogate_dataset), config.N_ATTRIB)\n",
    "\n",
    "surrogate_dataset_Y = surrogate_dataset['H Val'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(config.N_SEEDS):\n",
    "    surrogate = RandomForestRegressor(random_state=i)\n",
    "    surrogate.fit(surrogate_dataset_X, surrogate_dataset_Y)\n",
    "\n",
    "    # Save surrogate model\n",
    "    with open(f'../models/{config.DATASET_SAVE_NAME}-surrogate-RF-'+ str(i) +'.pickle', 'wb') as f:\n",
    "        pickle.dump([surrogate], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(config.N_SEEDS):\n",
    "    random.seed(i)\n",
    "    surrogate = SGDRegressor(random_state=i)\n",
    "    surrogate.fit(surrogate_dataset_X, surrogate_dataset_Y)\n",
    "\n",
    "    # Save surrogate model\n",
    "    with open(f'../models/{config.DATASET_SAVE_NAME}-surrogate-SGDR-'+ str(i) +'.pickle', 'wb') as f:\n",
    "        pickle.dump([surrogate], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(config.N_SEEDS):\n",
    "    random.seed(i)\n",
    "    surrogate = MLPRegressor(random_state=i)\n",
    "    surrogate.fit(surrogate_dataset_X, surrogate_dataset_Y)\n",
    "\n",
    "    # Save surrogate model\n",
    "    with open(f'../models/{config.DATASET_SAVE_NAME}-surrogate-MLP-'+ str(i) +'.pickle', 'wb') as f:\n",
    "        pickle.dump([surrogate], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
